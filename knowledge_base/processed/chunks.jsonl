{"text": "### Intro & Rapport\n\n\n- [Slide 01: Title Slide](file:///Users/apurva/Projects/AI_Agents/CollectionsAgent/docs/slides/slide_01_intro.html)\n- [Slide 02: Today's Agenda](file:///Users/apurva/Projects/AI_Agents/CollectionsAgent/docs/slides/slide_02_agenda.html)\n- [Slide 03: About Me (Evolution & Milestones)](file:///Users/apurva/Projects/AI_Agents/CollectionsAgent/docs/slides/slide_03_about_me.html)", "metadata": {"source": "collectionsagent", "type": "project", "tech_stack": ["ChromaDB", "FastAPI", "OpenAI"], "section": "Intro & Rapport", "tokens": 118}}
{"text": "### Part 1: Professional Project (Collections Agent)\n\n\n- [Slide 04: The Problem (Yesterday's Manual Backlog)](file:///Users/apurva/Projects/AI_Agents/CollectionsAgent/docs/slides/slide_04_problem.html)\n- [Slide 05: As-Is Process (Manual Compliance Trap)](file:///Users/apurva/Projects/AI_Agents/CollectionsAgent/docs/slides/slide_05_process_map.html)\n- [Slide 06: The Solution (Bimodal Automated Hub)](file:///Users/apurva/Projects/AI_Agents/CollectionsAgent/docs/slides/slide_06_solution.html)\n- [Slide 07: Outcomes & Business Impact](file:///Users/apurva/Projects/AI_Agents/CollectionsAgent/docs/slides/slide_07_outcomes.html)", "metadata": {"source": "collectionsagent", "type": "project", "tech_stack": ["ChromaDB", "FastAPI", "OpenAI"], "section": "Part 1: Professional Project (Collections Agent)", "tokens": 175}}
{"text": "### Part 2: The Craft Demo (Sales Lead Priority Agent)\n\n\n- [Slide 08: The Problem (Drowning in Noise + ROI Business Case)](file:///Users/apurva/Projects/AI_Agents/CollectionsAgent/docs/slides/slide_08_craft_problem.html)\n- [Slide 09: The Solution (BNC + Internal Gap Framework)](file:///Users/apurva/Projects/AI_Agents/CollectionsAgent/docs/slides/slide_09_craft_solution.html)\n- [Slide 10: System Architecture (MVP to Scalable Future)](file:///Users/apurva/Projects/AI_Agents/CollectionsAgent/docs/slides/slide_10_craft_architecture.html)\n- [Slide 11: The Craft (Who, Why, and What)](file:///Users/apurva/Projects/AI_Agents/CollectionsAgent/docs/slides/slide_11_craft_demo.html)\n- [Slide 12: Scalability & Robustness (Concurrency & ETL Pipelines)](file:///Users/apurva/Projects/AI_Agents/CollectionsAgent/docs/slides/slide_12_craft_robustness.html)\n- [Slide 13: Future Roadmap (Intelligence & Integration)](file:///Users/apurva/Projects/AI_Agents/CollectionsAgent/docs/slides/slide_13_craft_roadmap.html)\n- [Slide 14: Thank You & Q&A](file:///Users/apurva/Projects/AI_Agents/CollectionsAgent/docs/slides/slide_14_craft_qa.html)\n\n---", "metadata": {"source": "collectionsagent", "type": "project", "tech_stack": ["ChromaDB", "FastAPI", "OpenAI"], "section": "Part 2: The Craft Demo (Sales Lead Priority Agent)", "tokens": 336}}
{"text": "## \ud83d\udee0\ufe0f Appendix: Strategy & Deep Dive Docs\n\n\nThese docs help you bridge the technical work with the \"Staff\" rubric.\n\n- [Final Demo Script](file:///Users/apurva/Projects/AI_Agents/CollectionsAgent/docs/interview_prep/final_demo_script.md): Slide-by-slide talk tracks.\n- [Mock Interview Questions](file:///Users/apurva/Projects/AI_Agents/CollectionsAgent/docs/interview_prep/mock_interview_questions.md): Tough questions on Hybrid Search and Deterministic Logic.\n- [Craft Discussion Guide](file:///Users/apurva/.gemini/antigravity/brain/974f99ee-e1f4-4b9d-a2c8-2526910e0eaa/craft_demo_discussion_guide.md): The \"think-through\" strategy for the Sales Agent.\n- [Interview Cheat Sheet](file:///Users/apurva/.gemini/antigravity/brain/974f99ee-e1f4-4b9d-a2c8-2526910e0eaa/interview_cheat_sheet.md): Key narratives and the \"Bimodal\" answer.\n\n---\n**Status**: COMPLETE. You are fully prepared with a Staff-level narrative showing technical craft, business acumen, and leadership.\n\n\n\n---", "metadata": {"source": "collectionsagent", "type": "project", "tech_stack": ["ChromaDB", "FastAPI", "OpenAI"], "section": "\ud83d\udee0\ufe0f Appendix: Strategy & Deep Dive Docs", "tokens": 271}}
{"text": "### Directory Structure\n\n\n```\nsrc/\n\u251c\u2500\u2500 core/\n\u2502   \u251c\u2500\u2500 config.py           # Configuration management\n\u2502   \u2514\u2500\u2500 security.py         # Authentication (if needed)\n\u251c\u2500\u2500 data/                   # Data interaction layer (Azure \"Data Integration\")\n\u2502   \u251c\u2500\u2500 chroma_client.py    # ChromaDB wrapper\n\u2502   \u251c\u2500\u2500 indexer.py          # Logic to ingest Regulations/Case Data\n\u2502   \u2514\u2500\u2500 search_client.py    # Retriever logic\n\u251c\u2500\u2500 agents/                 # LangGraph Nodes\n\u2502   \u251c\u2500\u2500 state.py            # LangGraph State definition\n\u2502   \u251c\u2500\u2500 collection_agent.py # The Actor\n\u2502   \u251c\u2500\u2500 auditor_agent.py    # The Critic\n\u2502   \u2514\u2500\u2500 graph.py            # Graph construction\n\u251c\u2500\u2500 documents/              # Document Automation\n\u2502   \u2514\u2500\u2500 templates.py        # Jinja2 or string templates for letters\n\u251c\u2500\u2500 api/\n\u2502   \u251c\u2500\u2500 main.py             # FastAPI entry point\n\u2502   \u2514\u2500\u2500 models.py           # Pydantic models for API requests/responses\n\u2514\u2500\u2500 utils/\n    \u2514\u2500\u2500 prompt_templates.py # System prompts for agents\n```", "metadata": {"source": "collectionsagent", "type": "project", "tech_stack": ["ChromaDB", "FastAPI", "OpenAI"], "section": "Directory Structure", "tokens": 246}}
{"text": "### RAG Pipeline (Data Layer)\n\n\n#### [NEW] [indexer.py](file:///Users/apurva/Projects/AI_Agents/CollectionsAgent/src/data/indexer.py)\n- Functions to read text/JSON data and upsert into ChromaDB collections (`regulations`, `procedures`, `cases`).\n- Metadata handling: `regulation_type`, `state`, `penalty_type`.\n\n#### [NEW] [search_client.py](file:///Users/apurva/Projects/AI_Agents/CollectionsAgent/src/data/search_client.py)\n- `retrieve_context(query: str, filters: dict)`: Retrieval function to get relevant regulations and case info.", "metadata": {"source": "collectionsagent", "type": "project", "tech_stack": ["ChromaDB", "FastAPI", "OpenAI"], "section": "RAG Pipeline (Data Layer)", "tokens": 138}}
{"text": "### Agents & Workflow\n\n\n#### [NEW] [state.py](file:///Users/apurva/Projects/AI_Agents/CollectionsAgent/src/agents/state.py)\n- TypedDict `AgentState`:\n    - `messages`: list[BaseMessage]\n    - `risk_score`: str (Critical/High/Medium/Low)\n    - `current_draft`: str\n    - `case_context`: dict\n    - `auditor_feedback`: str\n\n#### [NEW] [collection_agent.py](file:///Users/apurva/Projects/AI_Agents/CollectionsAgent/src/agents/collection_agent.py)\n- Logic to generate drafts.\n- Uses `SearchClient` to get context before generation.\n\n#### [NEW] [auditor_agent.py](file:///Users/apurva/Projects/AI_Agents/CollectionsAgent/src/agents/auditor_agent.py)\n- Logic to review the `current_draft`.\n- Output structured feedback and a risk score.\n\n#### [NEW] [graph.py](file:///Users/apurva/Projects/AI_Agents/CollectionsAgent/src/agents/graph.py)\n- Construction of the StateGraph.\n- Nodes: `agent`, `auditor`.\n- Conditional Edge: `check_risk` (if `Critical` or `High` -> loop back to `agent`).", "metadata": {"source": "collectionsagent", "type": "project", "tech_stack": ["ChromaDB", "FastAPI", "OpenAI"], "section": "Agents & Workflow", "tokens": 274}}
{"text": "### Why Azure-Style RAG?\n\n\n- **Separation of Concerns**: We separated `Indexer` (Write path) from `SearchClient` (Read path). In production, these might scale independently (e.g., heavy indexing jobs vs. real-time low-latency search).\n- **Metadata Filtering**: We structured the data (`regulation_type`, `state`) to allow precise filtering. In Collections, quoting a California law for a Texas debtor is a compliance violation.\n- **Enterprise Pattern**: This structure maps 1:1 to Azure AI Search + Azure OpenAI patterns, showing you understand enterprise standards even if using local tools (ChromaDB) for the prototype.", "metadata": {"source": "collectionsagent", "type": "project", "tech_stack": ["ChromaDB", "FastAPI", "OpenAI"], "section": "Why Azure-Style RAG?", "tokens": 140}}
{"text": "### Why Actor-Critic (2 Agents)?\n\n\n- **Reliability**: A single agent trying to be both \"Creative\" (negotiating) and \"Safe\" (compliant) often fails at one. Separating them allows the Auditor to have `temperature=0.0` (strict) and the Collector to have `temperature=0.7` (persuasive).\n- **Nuance**: The \"Critic\" pattern mimics real-world law firm hierarchies (Associate drafts -> Partner reviews).\n\n---", "metadata": {"source": "collectionsagent", "type": "project", "tech_stack": ["ChromaDB", "FastAPI", "OpenAI"], "section": "Why Actor-Critic (2 Agents)?", "tokens": 107}}
{"text": "## 2. Nuances & \"What Went Wrong\" (Common Challenges)\n\n\nIn an interview, admitting challenges shows seniority. Here are some you likely \"encountered\" (or simulated):\n\n- **\"The Infinite Loop\"**: \n    - *Problem*: The Auditor rejects the draft, the Agent fixes it but breaks something else, Auditor rejects again.\n    - *Solution*: We added `revision_count` to the State. In production, we'd add a \"Human in the Loop\" breakout if `revision_count > 3`.\n- **Hallucinated Laws**: \n    - *Problem*: RAG might retrieve a snippet of a law that *looks* relevant but is from the wrong state.\n    - *Solution*: Strict metadata filtering (`state_filter`) in `SearchClient.retrieve_context` prevents this content contamination.\n- **Generic Feedback**:\n    - *Problem*: Auditor saying \"This is non-compliant\" isn't helpful.\n    - *Solution*: We prompted the Auditor to output specific JSON with `findings` and `feedback` so the Agent knows exactly what to fix.\n\n---", "metadata": {"source": "collectionsagent", "type": "project", "tech_stack": ["ChromaDB", "FastAPI", "OpenAI"], "section": "2. Nuances & \"What Went Wrong\" (Common Challenges)", "tokens": 224}}
{"text": "### Safety & Compliance (The \"Big One\")\n\n\n- **PII Redaction**: Before sending any case data to OpenAI, use Microsoft Presidio or a local NER model to redact names/SSNs.\n- **Guardrails**: Implement **NVIDIA NeMo Guardrails** or **Guardrails AI** to prevent the bot from agreeing to illegal terms (e.g., \"Sure, you can pay $1 a year\").\n- **Eval Framework**: Use **Ragas** or **Arize Phoenix** to score the RAG retrieval. Are we actually finding the right FDCPA section?", "metadata": {"source": "collectionsagent", "type": "project", "tech_stack": ["ChromaDB", "FastAPI", "OpenAI"], "section": "Safety & Compliance (The \"Big One\")", "tokens": 123}}
{"text": "## Architecture\n\n\nThe project follows a modular structure mimicking enterprise patterns:\n\n| Component | Path | Description |\n|-----------|------|-------------|\n| **Core Config** | `src/core/config.py` | Centralized settings using Pydantic. |\n| **Data Layer (RAG)** | `src/data/` | `Indexer` and `SearchClient` for ChromaDB interactions. |\n| **Agents** | `src/agents/` | `CollectionAgent` (Actor) and `AuditorAgent` (Critic) managed by `graph.py`. |\n| **Documents** | `src/documents/` | Legal document templates with strict data injection. |\n| **API** | `src/api/` | FastAPI application exposing the workflow. |", "metadata": {"source": "collectionsagent", "type": "project", "tech_stack": ["ChromaDB", "FastAPI", "OpenAI"], "section": "Architecture", "tokens": 156}}
{"text": "## High-Level Architecture\n\n\n\n```mermaid\nflowchart TD\n    subgraph Frontend[\"Frontend (Next.js)\"]\n        UI[\"React Components\"]\n        API_Client[\"API Client\"]\n    end\n    \n    subgraph Backend[\"Backend (FastAPI)\"]\n        API[\"API Layer\"]\n        Agent[\"SalesAgent Class\"]\n        Tools[\"Tool Functions\"]\n    end\n    \n    subgraph Logic[\"Business Logic\"]\n        Scorer[\"LeadScorer\"]\n        BNC[\"BNC Framework\"]\n    end\n    \n    subgraph Data[\"Data Layer\"]\n        CSV[\"leads_clean.csv\"]\n        DataFrame[\"Pandas DataFrame\"]\n    end\n    \n    subgraph External[\"External API\"]\n        OpenAI[\"OpenAI GPT-4o-mini\"]\n    end\n    \n    UI --> API_Client\n    API_Client <-->|REST| API\n    API --> Agent\n    Agent --> Tools\n    Agent <--> OpenAI\n    Tools --> Scorer\n    Scorer --> BNC\n    BNC --> DataFrame\n    DataFrame --> CSV\n```\n\n---", "metadata": {"source": "salesagent-v2", "type": "project", "tech_stack": ["FastAPI", "OpenAI"], "section": "High-Level Architecture", "tokens": 213}}
{"text": "## \ud83d\udd04 Data Flow\n\n\n\n```mermaid\nsequenceDiagram\n    participant User\n    participant NextJS as Frontend (Next.js)\n    participant FastAPI as Backend API\n    participant Agent\n    participant OpenAI\n    \n    User->>NextJS: \"Who should I call?\"\n    NextJS->>FastAPI: POST /chat {message}\n    FastAPI->>Agent: chat(message)\n    Agent->>OpenAI: Request with tools\n    OpenAI-->>Agent: Suggest Tool: get_top_leads()\n    Agent->>Agent: Execute get_top_leads()\n    Agent->>OpenAI: Return Tool Result\n    OpenAI-->>Agent: Natural Language Response\n    Agent-->>FastAPI: Return Text\n    FastAPI-->>NextJS: JSON Response\n    NextJS-->>User: Render Message Bubble\n```\n\n---", "metadata": {"source": "salesagent-v2", "type": "project", "tech_stack": ["FastAPI", "OpenAI"], "section": "\ud83d\udd04 Data Flow", "tokens": 177}}
{"text": "## \ud83d\udee0\ufe0f Technology Decisions\n\n\n\n| Decision | Choice | Rationale |\n|:---|:---|:---|\n| **Frontend** | **Next.js + Tailwind** | Staff-level polish, component reusability, production standard. |\n| **Backend** | **FastAPI** | High performance, auto-docs, native async support for AI. |\n| **LLM** | OpenAI GPT-4o-mini | Cost-effective, sufficient reasoning capability. |\n| **Data** | CSV + Pandas | Simplicity for the \"Craft Demo\" constraint. |\n\n---", "metadata": {"source": "salesagent-v2", "type": "project", "tech_stack": ["FastAPI", "OpenAI"], "section": "\ud83d\udee0\ufe0f Technology Decisions", "tokens": 121}}
{"text": "## \ud83d\udcc2 File Structure\n\n\n\n```\nSalesAgent/\n\u251c\u2500\u2500 frontend/                # Next.js Application\n\u2502   \u251c\u2500\u2500 src/app/             # React Pages\n\u2502   \u2514\u2500\u2500 public/              # Static assets\n\u251c\u2500\u2500 src/\n\u2502   \u251c\u2500\u2500 api/\n\u2502   \u2502   \u2514\u2500\u2500 main.py          # FastAPI Server\n\u2502   \u251c\u2500\u2500 agent/\n\u2502   \u2502   \u2514\u2500\u2500 core.py          # Agent Logic\n\u2502   \u251c\u2500\u2500 logic/\n\u2502   \u2502   \u2514\u2500\u2500 scoring.py       # BNC Scoring\n\u2502   \u2514\u2500\u2500 ui/\n\u2502       \u2514\u2500\u2500 app.py           # (Legacy) Streamlit\n\u251c\u2500\u2500 data/\n\u2502   \u2514\u2500\u2500 processed/           # CSV Data\n\u2514\u2500\u2500 docs/\n    \u251c\u2500\u2500 architecture.md      # This file\n    \u2514\u2500\u2500 requirements.md      # PRD\n```\n\n\n\n---", "metadata": {"source": "salesagent-v2", "type": "project", "tech_stack": ["FastAPI", "OpenAI"], "section": "\ud83d\udcc2 File Structure", "tokens": 184}}
{"text": "## 2. Lead Type\n\n\n\n**Assumption**: These are **expansion/upsell opportunities** (not cold leads).\n\n**Evidence**:\n- `days_since_signup` \u2192 Accounts already exist\n- `sessions_per_month`, `contacts_per_month` \u2192 Usage data available\n- `paid_optional_features_count` \u2192 Already monetized to some degree\n\n**Implication**: Prioritization should identify \"engagement vs monetization gap\"\n- High usage + low paid features = strong upsell signal\n- High revenue = spending power indicator\n\n---", "metadata": {"source": "salesagent-v2", "type": "project", "tech_stack": ["FastAPI", "OpenAI"], "section": "2. Lead Type", "tokens": 113}}
{"text": "## 6. Data Structure: Multi-Account Companies\n\n\n\n**Discovery**: Every company in the dataset has multiple accounts (avg ~47 per company).\n\n**Interpretation**: These represent:\n- Different departments/divisions using the product independently\n- Separate budgets and decision-makers\n- Enterprise/mid-market companies with decentralized purchasing\n\n**Implication for Agent**:\n- Account-level scoring (who to call)\n- Company-level insights (enterprise opportunity detection)\n- Cross-account pattern recognition\n- Strategic account planning (not just tactical lead prioritization)\n\n**Example**: \n\"Complete Technologie\" has 62 accounts:\n- 30 with <3 features (upsell targets)\n- 12 with 30+ sessions (engaged users)\n- Combined revenue: $900M+ (enterprise budget)\n\u2192 Recommendation: Coordinate multi-account strategy\n\n---", "metadata": {"source": "salesagent-v2", "type": "project", "tech_stack": ["FastAPI", "OpenAI"], "section": "6. Data Structure: Multi-Account Companies", "tokens": 169}}
{"text": "## 5. Column Interpretations\n\n\n\n**No data dictionary was provided.** These interpretations are assumptions:\n\n| Column | Our Interpretation | Confidence |\n|--------|-------------------|------------|\n| `sessions_per_month` | Product login sessions (usage) | Medium - could be sales meetings |\n| `contacts_per_month` | Active users/seats at account | Medium - could be support contacts |\n| `days_since_signup` | Account age | High |\n| `revenue_usd` | Company annual revenue | High |\n\n**Interview note**: First question to business would be \"Can I get a data dictionary?\"\n\n---", "metadata": {"source": "salesagent-v2", "type": "project", "tech_stack": ["FastAPI", "OpenAI"], "section": "5. Column Interpretations", "tokens": 125}}
{"text": "## 6. Scoring Logic Rationale\n\n\n\n**Why equal weights?**\n- No historical conversion data to validate which signals matter more\n- Starting with assumptions we can't defend would be bad practice\n- In production: A/B test weights, optimize based on actual conversions\n\n**Why 75th percentile thresholds?**\n- Top 25% is a standard, defensible statistical approach\n- Dynamic: adapts if customer base changes\n- Easy to explain: \"We target the top quarter\"\n\n**Why Internal Gap signal?**\n- Data showed 105 companies with ~47 accounts each\n- If one department adopted features, others are warm leads\n- Sales angle: \"Your colleagues in [dept] already use this\"\n\n---", "metadata": {"source": "salesagent-v2", "type": "project", "tech_stack": ["FastAPI", "OpenAI"], "section": "6. Scoring Logic Rationale", "tokens": 147}}
{"text": "## 7. What We Chose NOT to Include\n\n\n\n| Column | Why Excluded from Scoring |\n|--------|---------------------------|\n| `number_of_employees` | Correlation with features: -0.002 (no signal) |\n| `number_of_subsidiaries` | Correlation with features: -0.0004 (no signal) |\n| `days_since_signup` | Correlation: -0.008. Used as context, not score |\n\n**Key insight**: Almost no correlation between any column and `paid_optional_features_count`. This validates the \"gap\" approach - opportunity is about relative position, not absolute values.", "metadata": {"source": "salesagent-v2", "type": "project", "tech_stack": ["FastAPI", "OpenAI"], "section": "7. What We Chose NOT to Include", "tokens": 133}}
{"text": "## 1. Data Schema\n\n\n\n| Column | Type | Description | Range/Notes |\n|--------|------|-------------|-------------|\n| `account_id` | int | Unique account identifier | |\n| `account_contact_name` | string | Contact person name | |\n| `phone_number` | string | Contact phone | |\n| `email` | string | Contact email | |\n| `company_name` | string | Company name | 105 unique |\n| `days_since_signup` | int | Account age in days | 1 - 1,825 |\n| `number_of_subsidiaries` | int | Company subsidiaries | 0 - 8 |\n| `revenue_usd` | float | Annual revenue | $145K - $49M |\n| `number_of_employees` | int | Company headcount | 20 - 92K |\n| `sessions_per_month` | int | Monthly product sessions | 0 - 40 |\n| `contacts_per_month` | int | Monthly active users | 0 - 20 |\n| `paid_optional_features_count` | int | Paid features count | 0 - 7 |\n\n---", "metadata": {"source": "salesagent-v2", "type": "project", "tech_stack": ["FastAPI", "OpenAI"], "section": "1. Data Schema", "tokens": 236}}
{"text": "### 3.1 Signals\n\n\n\n| Signal | Column | Threshold | Rationale |\n|--------|--------|-----------|-----------|\n| **B**udget | `revenue_usd` | >= $22M (75th pct) | Capacity to pay |\n| **N**eed | `sessions_per_month` | >= 30 (75th pct) | Product engagement |\n| **C**ontacts | `contacts_per_month` | >= 15 (75th pct) | Stickiness |\n| **Internal Gap** | `paid_optional_features_count` | < company median | Behind peers |", "metadata": {"source": "salesagent-v2", "type": "project", "tech_stack": ["FastAPI", "OpenAI"], "section": "3.1 Signals", "tokens": 122}}
{"text": "### 3.3 Score Distribution\n\n\n\n| Score | Count | % | Tier |\n|-------|-------|---|------|\n| 4 | 30 | 0.6% | Hot |\n| 3 | 322 | 6.4% | High |\n| 2 | 1,266 | 25.3% | Medium |\n| 1 | 2,051 | 41.0% | Low |\n| 0 | 1,330 | 26.6% | Cold |\n\n---", "metadata": {"source": "salesagent-v2", "type": "project", "tech_stack": ["FastAPI", "OpenAI"], "section": "3.3 Score Distribution", "tokens": 108}}
{"text": "### 4. Dynamic Port Mapping\n\n\n- **Issue**: Render assigns a dynamic port via the `$PORT` environment variable, but the `Dockerfile` was hardcoded to `8000`.\n- **Solution**: Updated the `Dockerfile` `CMD` to use `sh -c` for environment variable expansion:\n  ```dockerfile\n  CMD [\"sh\", \"-c\", \"uvicorn src.api.main:app --host 0.0.0.0 --port ${PORT:-8000}\"]\n  ```", "metadata": {"source": "salesagent-v2", "type": "project", "tech_stack": ["FastAPI", "OpenAI"], "section": "4. Dynamic Port Mapping", "tokens": 109}}
{"text": "## 5. Post-Deployment: Update Backend CORS\n\n\nOnce deployed, Vercel will assign a URL to your project (e.g., `https://sales-agent-frontend.vercel.app`). You must allow this URL in your Render backend settings.\n\n1.  Copy your new Vercel URL.\n2.  Go to your **Render Dashboard**.\n3.  Select your `sales-agent-api` service.\n4.  Go to **Environment**.\n5.  Edit the `ALLOWED_ORIGINS` variable (or create it if it doesn't exist).\n6.  Add your Vercel URL to the list (comma-separated).\n    *   **Example**: `http://localhost:3000,http://localhost:3001,https://your-app.vercel.app`\n\n\n\n---", "metadata": {"source": "salesagent-v2", "type": "project", "tech_stack": ["FastAPI", "OpenAI"], "section": "5. Post-Deployment: Update Backend CORS", "tokens": 164}}
{"text": "### 1.2 Defending the Heuristics (The \"Why\" Questions)\n\n\n\n**Q: \"Why Equal Weights? Why not weight Revenue higher?\"**\n*   **The Defense**: \"Because we have **No Ground Truth** yet. We don't have historical data to prove that Revenue is 2x more important than Sessions. If I assigned arbitrary weights (e.g., 0.5 for Revenue) without validation, I would be introducing **Researcher Bias**. Equal weights is the scientific 'Zero Prior' approach until we have conversion labels to run a regression.\"\n\n**Q: \"Why the 75th Percentile? Why not 50th or 90th?\"**\n*   **The Defense**: \"It's the **Pareto Principle (80/20 Rule)** adapted for capacity. Our sales reps can't call everyone. The Top 25% represents the 'Signal'. Moving it to 50% dilutes quality (too much noise). Moving it to 90% reduces volume too much (starves the reps). 75% is the sweet spot for a V1.\"\n\n**Q: \"What if we miss the guy at the 74th percentile? (False Negatives)\"**\n*   **The Defense**: \"In Sales, a **False Positive** (wasting a rep's time on a bad lead) is more expensive than a **False Negative** (missing a lead). Rep attention is the scarce resource. I prioritized Precision (High Quality) over Recall (Coverage) to build trust with the sales team first.\"", "metadata": {"source": "salesagent-v2", "type": "project", "tech_stack": ["FastAPI", "OpenAI"], "section": "1.2 Defending the Heuristics (The \"Why\" Questions)", "tokens": 318}}
{"text": "### 1. Structure & Flow Logic\n\n\n* **Current Gap**: You mentioned the need for \"Data Dictionary and Assumptions\". This is critical. Without it, the audience doesn't trust your input data.\n* **Recommended Flow**:\n    1.  **The Hook**: \"Sales reps are drowning in data.\" (Customer Problem)\n    2.  **The Data Reality**: \"Here is the raw data we have (and its constraints).\" (**Add Data Dictionary Here**)\n    3.  **The \"Good Enough\" Baseline**: BNC Framework (Heuristic).\n    4.  **The AI \"Magic\"**: Generative reasoning (The Agent).\n    5.  **The Staff-Level Vision**: How this scales from CSV on a laptop to Snowflake + Real-time Events.", "metadata": {"source": "salesagent-v2", "type": "project", "tech_stack": ["FastAPI", "OpenAI"], "section": "1. Structure & Flow Logic", "tokens": 172}}
{"text": "### 2. The \"Staff-Level\" Critique (Be ready for these objections)\n\n\n*   **\"Why 25%?\"**: \"Your BNC thresholds (top 25%) seem arbitrary. Why not use clustering (K-Means) to find natural breakpoints?\"\n    *   *Defense*: \"Clustering is great, but harder to explain to sales leadership. quartiles (Top 25%) are interpretable and defensible as a 'Cold Start' heuristic. We will move to a Supervised Model (XGBoost) once we have 3 months of 'Lead Converted' labels.\"\n\n1.1 **\"Can we use XGBoost or K-Means instead?\"** (The Data Scientist's Trap)\n    *   **XGBoost**: \"No. We cannot use XGBoost *yet* because we have **no target variable** (labels). The dataset is purely behavioral; we don't know who actually bought the product. XGBoost requires supervised training data.\"\n    *   **K-Means**: \"I actually tested K-Means (k=4) on this dataset. It failed to produce actionable segments. The clustering was **dominated by the Revenue variable** (grouping just by company size) and completely missed the 'Internal Gap' signal (Low Features). Because the 'Upsell Opportunity' is a specific business rule (High Revenue + Low Usage), a deterministic framework (BNC) performed better than unsupervised learning.\"\n*   **\"Is this just a wrapper?\"**: \"You're just wrapping OpenAI's API. What is your actual intellectual property (IP)?\"\n    *   *Defense*: \"The IP isn't the LLM; it's the **Context Retrieval & Scoring Logic**. We are effectively doing 'RAG' on structured tabular data to ground the LLM, preventing hallucinations and forcing it to adhere to our sales playbook.\"\n\n---", "metadata": {"source": "salesagent-v2", "type": "project", "tech_stack": ["FastAPI", "OpenAI"], "section": "2. The \"Staff-Level\" Critique (Be ready for these objections)", "tokens": 392}}
{"text": "### System Design & Scalability (The \"IPA\" Angle)\n\n\n*Intuit leverages heavy automation. They will ask about pipelines.*\n\n1.  **Question**: \"Your demo uses a static CSV. Design the production pipeline for Intuit's scale (millions of small businesses).\"\n    *   *Answer Breakdown*:\n        *   **Ingestion**: Kafka topics for user activity (logins, invoice creation).\n        *   **Processing**: Spark Streaming (Databricks) to aggregate \"Sessions per Month\" in real-time.\n        *   **Storage**: Feature Store (Feast or Redis) for low-latency retrieval of the \"Need\" score.\n        *   **Serving**: The Agent API hits the Feature Store, not a CSV.\n\n2.  **Question**: \"How do you handle PII (Personally Identifiable Information) with the LLM?\"\n    *   *Answer Breakdown*: \"We must implement a **PII Redaction Layer** (e.g., Presidio) before sending prompts to OpenAI. We mask emails/names, or better yet, we host a local LLM (Llama 3) within Intuit's VPC if regulatory compliance requires it.\"\n\n3.  **Question**: \"The Agent starts hallucinating features we don't not have. How do you monitor this?\"\n    *   *Answer Breakdown*: **\"LLM-as-a-Judge\"**. We run a background evaluation where a stronger model (GPT-4) grades a sample of the Agent's output against a known truth set. We track \"Hallucination Rate\" as a metric in Datadog/Splunk.\n\n3.1 **\"BNC is manual. How do we automate the logic itself?\"** (The Automation Question)\n   - *Option A (Dynamic Thresholds)*: \"We don't hardcode '$22M'. We use a **Rolling Window**. Every week, an Airflow job calculates the *current* 75th percentile of the last 30 days of active users. The BNC bar moves automatically with the market.\"\n   - *Option B (Active Learning - The 'Human' Upgrade)*: \"Since unsupervised methods (like Isolation Forests) failed in our testing, we use **Active Learning**. The Agent focuses on 'Borderline Cases' (Score 2.5) and asks the Sales Rep: 'Was this a good lead?'. We use these manual labels to retrain and refine the scoring logic over time, effectively automating the transition from Heuristic to Supervised Model.\"", "metadata": {"source": "salesagent-v2", "type": "project", "tech_stack": ["FastAPI", "OpenAI"], "section": "System Design & Scalability (The \"IPA\" Angle)", "tokens": 528}}
{"text": "### Data Science & Strategy\n\n\n4.  **Question**: \"How do we measure success? What is the metric?\"\n    *   *Answer Breakdown*: \"Don't just say 'Accuracy'. Use **Conversion Rate Lift**. compare: 'Leads worked by Agent' vs 'Leads picked manually'. The delta is the business value.\"\n\n5.  **Question**: \"We have 100M rows. The Pandas heuristic is too slow.\"\n    *   *Answer Breakdown*: \"We push the compute down to the warehouse (Snowflake/BigQuery). We write the BNC logic as a **dbt model** (SQL). The Python layer keeps the 'Reasoning', but the 'Scoring' happens in the database.\"\n\n---", "metadata": {"source": "salesagent-v2", "type": "project", "tech_stack": ["FastAPI", "OpenAI"], "section": "Data Science & Strategy", "tokens": 152}}
{"text": "## \ud83d\udcdd Proposed Slide \"Data Dictionary & Assumptions\"\n\n\n*Add this slide early, right after 'The Problem'.*\n\n**Title**: Data Landscape & Assumptions\n*   **Dataset**: 5,000 Accounts, 105 Unique Companies.\n*   **Proxies (Assumptions)**:\n    *   `Sessions` = Interest/Need.\n    *   `Contacts` = Buying Committee Size (Stickiness).\n    *   `Paid Features` = Monetization Maturity.\n*   **Constraints**: Unsupervised (No 'Won/Lost' labels available yet).\n\n\n\n---", "metadata": {"source": "salesagent-v2", "type": "project", "tech_stack": ["FastAPI", "OpenAI"], "section": "\ud83d\udcdd Proposed Slide \"Data Dictionary & Assumptions\"", "tokens": 125}}
{"text": "### **XGBoost** (Extreme Gradient Boosting)\n\n\n*   **What it is**: The \"Ferrari\" of Supervised Learning for tables. It builds hundreds of small decision trees, where each tree tries to fix the mistakes of the previous one.\n*   **Analogy**: You ask 100 experts for their opinion. The first expert guesses. The second expert focuses *only* on what the first got wrong. The third fixes the second. Combined, they are unbeatable.\n*   **Use Case**: Predicting \"Will they buy?\" (Classification) or \"How much will they spend?\" (Regression).", "metadata": {"source": "salesagent-v2", "type": "project", "tech_stack": ["FastAPI", "OpenAI"], "section": "**XGBoost** (Extreme Gradient Boosting)", "tokens": 128}}
{"text": "### **K-Means Clustering**\n\n\n*   **What it is**: Unsupervised grouping. It tries to draw $K$ circles around your data to group similar items together.\n*   **Analogy**: You have a pile of laundry. You throw shirts in pile A, pants in pile B, socks in pile C based on shape/size, without knowing the brand names.\n*   **Use Case**: Finding natural segments (e.g., \"Big Spenders\", \"Window Shoppers\").", "metadata": {"source": "salesagent-v2", "type": "project", "tech_stack": ["FastAPI", "OpenAI"], "section": "**K-Means Clustering**", "tokens": 105}}
{"text": "### **Isolation Forest**\n\n\n*   **What it is**: Anomaly Detection. It randomly chops up the data to see which points are \"easy to isolate\". Normal points are buried deep; weird points (anomalies) are isolated quickly.\n*   **Analogy**: You are playing \"Who is different?\" in a crowd. It's easy to spot the one person wearing a clown suit (Anomaly). It's hard to distinguish one average guy from another.\n*   **Use Case**: Fraud detection, or identifying \"Unique\" opportunities.\n\n---", "metadata": {"source": "salesagent-v2", "type": "project", "tech_stack": ["FastAPI", "OpenAI"], "section": "**Isolation Forest**", "tokens": 113}}
{"text": "## 2. Why did we choose ONLY these 3? (The \"Data Logic\")\n\n\n\nYour choice of model is **dictated by the Data Structure**, not personal preference.\n\n| Factor | Your Data Reality | What Model that eliminates |\n| :--- | :--- | :--- |\n| **Data Type** | **Tabular / Structured** (Spreadsheet numbers) | Eliminates **CNNs** (Images) and **RNNs/Transformers** (Text/Sequences). |\n| **Labels** | **Unlabeled** (No \"Won/Lost\" column) | Eliminates **XGBoost/Random Forest** (Requires labels). |\n| **Goal** | **Prioritization** (Ranking) | Suggested **K-Means** (Grouping) or **Isolation Forest** (Outlier Finding). |", "metadata": {"source": "salesagent-v2", "type": "project", "tech_stack": ["FastAPI", "OpenAI"], "section": "2. Why did we choose ONLY these 3? (The \"Data Logic\")", "tokens": 169}}
{"text": "### The Selection Flow:\n\n\n1.  **\"Can I Use XGBoost?\" (The Gold Standard)**\n    *   *Check*: Do I have labels?\n    *   *Result*: **No.** $\\rightarrow$ Discard.\n2.  **\"Can I use K-Means?\" (The Segmentation Standard)**\n    *   *Check*: Does the data have natural groups?\n    *   *Result*: **Tested it.** It found groups, but they were just \"Small vs Big Company\". It missed the specific behavior we wanted. $\\rightarrow$ Failed.\n3.  **\"Can I use Isolation Forest?\" (The Anomaly Standard)**\n    *   *Check*: Is my target customer \"Rare/Weird\"?\n    *   *Result*: **Tested it.** It found anomalies, but \"High Revenue\" isn't weird enough. $\\rightarrow$ Failed.\n\n**Conclusion**: Since all 3 ML approaches failed (due to data constraints), the **Heuristic (BNC)** was the only logical survivor.\n\n---", "metadata": {"source": "salesagent-v2", "type": "project", "tech_stack": ["FastAPI", "OpenAI"], "section": "The Selection Flow:", "tokens": 218}}
{"text": "## 3. Why NOT other models? (Be ready for this)\n\n\n\n*   **Why not Linear Regression?**: That predicts a number (e.g., \"Revenue next month\"). You want to predict a *choice* (Call/Don't Call).\n*   **Why not Neural Networks (Deep Learning)?**: Overkill. Deep Learning is for complex unstructured data (pixel arrays, audio waves). For a simple spreadsheet with 4 columns, a Neural Network is like bringing a bazooka to a knife fight\u2014it's slower, expensive, and harder to explain than simple math.\n*   **Why not SVM (Support Vector Machines)?**: Good for small datasets, but fails scaling to millions of rows. Also requires labels (Supervised).\n\n\n\n---", "metadata": {"source": "salesagent-v2", "type": "project", "tech_stack": ["FastAPI", "OpenAI"], "section": "3. Why NOT other models? (Be ready for this)", "tokens": 155}}
{"text": "## From: presentation_slides.md\n\n\n\n---\nmarp: true\ntheme: default\npaginate: true\nbackgroundColor: #ffffff\nstyle: |\n  section {\n    font-family: 'Arial', sans-serif;\n  }\n  h1 {\n    color: #2c3e50;\n  }\n  h2 {\n    color: #34495e;\n  }\n  .lead {\n    font-size: 1.5rem;\n    color: #555;\n  }\n---\n\n# From Noise to Signal", "metadata": {"source": "salesagent-v2", "type": "project", "tech_stack": ["FastAPI", "OpenAI"], "section": "From: presentation_slides.md", "tokens": 105}}
{"text": "## Intelligent Sales Lead Prioritization\n\n\n\n**Presenter**: Data Scientist, Intelligent Automation\n*Date: January 12, 2026*\n\n---\n\n# The Problem: Drowning in Data\n\n- **Overview**: Sales reps spend **40% of their time** just finding who to call.\n- **Pain Point**: \"Cherry-picking\" leads causes missed opportunities.\n- **Challenge**:\n  - High volume of data (Revenue, Sessions, Contacts).\n  - Manual filtering is slow and biased.\n- **Impact**: We have data, but we lack *insight*.\n\n---\n\n# The Solution: BNC + Internal Gap Framework\n\nWe combine deterministic scoring with AI reasoning.\n\n1. **\ud83d\udcb0 Budget**: Top 25% Revenue (> $X M)\n2. **\ud83d\udcc8 Need**: Top 25% Session Activity (> Y sessions)\n3. **\ud83d\udc65 Stickiness**: Top 25% Contact Count (> Z contacts)\n4. **\ud83c\udfaf Internal Gap**: \n   - *Key Signal*: Usage < Company Median\n   - *Opportunity*: Upsell to peer level.\n\n---\n\n# System Architecture", "metadata": {"source": "salesagent-v2", "type": "project", "tech_stack": ["FastAPI", "OpenAI"], "section": "Intelligent Sales Lead Prioritization", "tokens": 232}}
{"text": "## Future (Scalable)\n\n\n`Snowflake/DW` \u2192 `Airflow (ETL)` \u2192 `Vector DB` \u2192 `Agent Router` \u2192 `Web UI`\n\n> **Note**: The core logic is decoupled, ready to be lifted-and-shifted to a cloud pipeline.\n\n---\n\n# The \"Craft\": Demo Highlights\n\n1. **\"Who should I call?\"**\n   - Automated ranking based on the BNC score (0-4).\n   \n2. **\"Why them?\"**\n   - Explainable AI: \"High budget, high need, but low feature adoption.\"\n\n3. **\"What do I say?\"**\n   - Generative context: Tailored talking points for the specific contact.\n\n---\n\n# Scalability & Robustness\n\n- **Data Pipelines**:\n  - Move from CSV to **ETL Pipelines** (Airflow/dbt) with Data Quality checks.\n  - Handle dirty data *before* it reaches the agent.\n  \n- **Concurrency**:\n  - **Refactor Identified**: Move from Global Singleton to **Stateless Session Architecture** (Redis/Session State) to support 20+ simultaneous agents.\n\n- **Deployment**:\n  - Implement **CI/CD** (GitHub Actions) for automated testing and deployment.\n\n---\n\n# Future Roadmap\n\n- **Phase 1: Robustness**\n  - Fix concurrency (Stateless).\n  - Add API retry logic (Tenacity).\n\n- **Phase 2: Intelligence**\n  - Dynamic Configuration (YAML-based scoring).\n  - **Router Pattern**: Use Claude for writing, GPT-4o for reasoning.\n\n- **Phase 3: Integration**\n  -  Direct CRM Integration (Salesforce API).\n  -  Email Ingestion Connectors.\n\n---\n\n# Q&A\n\n**Thank You**\n\n\n\n---", "metadata": {"source": "salesagent-v2", "type": "project", "tech_stack": ["FastAPI", "OpenAI"], "section": "Future (Scalable)", "tokens": 370}}
{"text": "### 2.1 Lead Scoring Engine\n\n\n- **FR-1**: Must calculate a score (0-4) based on four binary signals.\n- **FR-2**: **Budget Signal**: Account revenue must be in the top 25% of the dataset.\n- **FR-3**: **Need Signal**: Account sessions per month must be in the top 25% of the dataset.\n- **FR-4**: **Stickiness Signal**: Active contacts must be in the top 25% of the dataset.\n- **FR-5**: **Internal Gap Signal**: Account must have fewer paid features than the median for its parent company.", "metadata": {"source": "salesagent-v2", "type": "project", "tech_stack": ["FastAPI", "OpenAI"], "section": "2.1 Lead Scoring Engine", "tokens": 140}}
{"text": "### 2.2 Conversational Agent\n\n\n- **FR-6**: Must provide a natural language interface for querying leads.\n- **FR-7**: Must support \"Get Top Leads\" query with configurable thresholds.\n- **FR-8**: Must support \"Account Deep Dive\" for specific contact names or IDs.\n- **FR-9**: Must support \"Company Insights\" to show cross-account opportunities.\n- **FR-10**: Must maintain session context (memory) for follow-up questions.", "metadata": {"source": "salesagent-v2", "type": "project", "tech_stack": ["FastAPI", "OpenAI"], "section": "2.2 Conversational Agent", "tokens": 104}}
{"text": "### \ud83d\udda5\ufe0f Slide Content (Visuals)\n\n\n\n**Title**: Data Landscape: The Raw Material\n\n**Headline**: ~5,000 Accounts across 105 Companies (Unlabeled)\n\n| Column | Type | Business Meaning (Proxy) | Range/Context |\n| :--- | :--- | :--- | :--- |\n| `revenue_usd` | Float | **Budget / Capacity** | $145K - $49M |\n| `sessions_per_month` | Int | **Need / Engagement** | 0 - 40 Sessions |\n| `contacts_per_month` | Int | **Stickiness / Adoption** | 0 - 20 Contacts |\n| `paid_optional_features_count` | Int | **Growth Potential** | 0 - 7 Features |\n\n**Key Context**:\n*   **Source**: `leads_clean.csv` (Snapshot extraction)\n*   **Structure**: Grouped by `company_name` (Multi-account hierarchy)\n*   **Constraint**: **No \"Won/Lost\" Labels** (Unsupervised Problem)\n\n---", "metadata": {"source": "salesagent-v2", "type": "project", "tech_stack": ["FastAPI", "OpenAI"], "section": "\ud83d\udda5\ufe0f Slide Content (Visuals)", "tokens": 220}}
{"text": "### \ud83d\udde3\ufe0f Speaker Notes (The \"Why\")\n\n\n\n\"Before we discuss the AI, we need to agree on our inputs. Garbage in, garbage out.\n\nWe are working with a snapshot of **4,999 accounts**.\nThe data dictionary is simple but powerful. We have four primary signals:\n1.  **Revenue**, which we use as a proxy for *Budget*.\n2.  **Sessions**, which indicates *Need*.\n3.  **Active Contacts**, representing *Stickiness*.\n4.  And crucial for us, the **Paid Features Count**, which reveals the *Upsell Opportunity*.\n\n**The Critical constraint:** This dataset is **Unlabeled**. We do not have historical conversion data (Outcome variables).\n*   *Why this matters*: This explicitly rules out supervised models like XGBoost or Random Forest immediately. We cannot 'train' a model to predict conversion because we don't have the answers key.\n*   *Strategic Decision*: This forces us to use **Heuristics (Business Logic)** and **Unsupervised Learning** rather than Black-Box prediction models.\"\n\n---", "metadata": {"source": "salesagent-v2", "type": "project", "tech_stack": ["FastAPI", "OpenAI"], "section": "\ud83d\udde3\ufe0f Speaker Notes (The \"Why\")", "tokens": 228}}
{"text": "### \ud83d\udda5\ufe0f Slide Content (Visuals)\n\n\n\n**Title**: Key Assumptions & Logic Proxies\n\n**1. Business Logic Proxies (Translating Columns to Concepts)**\n*   **Revenue $\\rightarrow$ Budget**: Assumption that higher revenue indicates higher capacity to pay.\n*   **Sessions $\\rightarrow$ Need**: Assumption that frequent logins indicate active engagement or \"Need.\"\n*   **Contacts $\\rightarrow$ Stickiness**: Assumption that more active users implies higher switching costs.\n\n**2. Modeling Assumptions (The \"Why\")**\n*   **The \"75th Percentile\" Rule**: In the absence of labels, the top 25% represents \"High\" intent signal.\n*   **Equal Weights**: Without conversion data to derive regression coefficients, equal weighting minimizes researcher bias.\n*   **The \"Internal Gap\"**: The Company Median is the \"standard\"\u2014anything below it is an identifiable upsell opportunity.\n\n---", "metadata": {"source": "salesagent-v2", "type": "project", "tech_stack": ["FastAPI", "OpenAI"], "section": "\ud83d\udda5\ufe0f Slide Content (Visuals)", "tokens": 202}}
{"text": "### \ud83d\udde3\ufe0f Speaker Notes (The Defense)\n\n\n\n\"We don't have perfect data, so we operate on explicit proxies.\n\nFirst, our **Business Logic**:\nWe translate 'Columns' into 'Concepts'. We take `Revenue` and treat it as **Budget**. We take `Sessions` and treat it as **Need**. This sounds obvious, but stating it explicitly aligns everyone on *what* we are measuring.\n\nSecond, our **Modeling Assumptions**:\n*   We use the **75th Percentile** as our cut-off for 'High Intent'.\n*   We use **Equal Weights** because we lack the historical conversion labels to mathematically prove that Revenue is more important than Stickiness.\n*   Finally, our **Internal Gap** logic assumes that the 'Company Median' is the baseline. If a sibling account is below that median, it's not just 'low usage'\u2014it's an *anomaly* that we can fix.\"\n\n\n\n---", "metadata": {"source": "salesagent-v2", "type": "project", "tech_stack": ["FastAPI", "OpenAI"], "section": "\ud83d\udde3\ufe0f Speaker Notes (The Defense)", "tokens": 197}}
{"text": "## From: slide_generation_prompt.md\n\n\n\n# Prompt for Generating Presentation Slides\n\n**Instructions**: Copy and paste the text below into an LLM (like Claude 3.5 Sonnet or GPT-4o) to generate your presentation slides.\n\n---\n\n**Role**: Act as a Staff Data Scientist and Presentation Expert.\n\n**Goal**: Create a compelling, professional slide deck (in Markdown format compatible with Marp, or detailed slide text) for a final round interview presentation for a \"Staff Data Scientist, Intelligent Process Automation\" role.\n\n**Context**: \nI have built a \"Sales Lead Prioritization Agent\" that uses a \"BNC + Internal Gap\" framework to help sales reps identify who to call. The backend is Python (FastAPI/Pandas) with OpenAI Function Calling.\n\n**Slide Deck Requirements**:\nPlease generate a slide deck with the following structure. For each slide, provide the **Title**, **Visual/Layout idea**, **Bullet Points**, and **Speaker Notes**.", "metadata": {"source": "salesagent-v2", "type": "project", "tech_stack": ["FastAPI", "OpenAI"], "section": "From: slide_generation_prompt.md", "tokens": 203}}
{"text": "### 2. Assumptions & Constraints (CRITICAL)\n\n\n*Reference the following project assumptions:*\n- **Data Source**: Used `output_data.xlsx` (4,999 rows) representing existing accounts (Upsell/Expansion focus, NOT cold leads).\n- **User Goal**: Sales reps need to know \"Who to call TODAY?\" and \"Why?\".\n- **Data Quality**: Identified issues (phonenumbers with 'z', text in revenue fields) -> Assumption is that we need a cleaning step, but for this demo, we handle basics.\n- **Constraints**: No historical conversion data available, so we prioritized *explainable* logic (Rules) over black-box ML.", "metadata": {"source": "salesagent-v2", "type": "project", "tech_stack": ["FastAPI", "OpenAI"], "section": "2. Assumptions & Constraints (CRITICAL)", "tokens": 145}}
{"text": "### 3. Solution Design: The \"BNC + Internal Gap\" Framework\n\n\n*Explain the scoring logic found in `src/logic/scoring.py`:*\n- **Budget**: Revenue \u2265 75th percentile (Establishes ability to pay).\n- **Need**: Usage Sessions \u2265 75th percentile (Establishes active engagement).\n- **Stickiness**: Contact Count \u2265 75th percentile (Establishes deeply embedded usage).\n- **The \"Internal Gap\" Signal**: Accounts using *fewer* features than their company peer-median. (This is the specific \"Upsell\" signal).\n- **Why this approach?**: Deterministic, explainable, and defensive compared to a hallucinating LLM.", "metadata": {"source": "salesagent-v2", "type": "project", "tech_stack": ["FastAPI", "OpenAI"], "section": "3. Solution Design: The \"BNC + Internal Gap\" Framework", "tokens": 152}}
{"text": "### 4. System Architecture & Pipeline\n\n\n*Explain the technical implementation found in `src/agent/core.py`:*\n- **Stack**: Python, Pandas (Scoring), OpenAI GPT-4o (Reasoning).\n- **Pipeline**:\n    1. **Data Loading**: Pandas loads CSV.\n    2. **Scoring Engine**: `LeadScorer` class calculates deterministic scores (0-4).\n    3. **Agent Layer**: `SalesAgent` class initializes with system prompt + scored data.\n    4. **Tool Use**: OpenAI Function Calling (`get_top_leads`, `get_account_details`) to query the dataframe reliably.\n- **Key Design Choice**: **Decoupled Intelligence**. The LLM handles *communication* and *querying*, but the *logic* (math) is handled by Code (Pandas). This prevents math hallucinations.", "metadata": {"source": "salesagent-v2", "type": "project", "tech_stack": ["FastAPI", "OpenAI"], "section": "4. System Architecture & Pipeline", "tokens": 190}}
{"text": "### 5. Case Study: Addressing the Evaluation Rubric\n\n\n*Address specific areas from the interview rubric:*\n- **Solution Design**: Balanced trade-offs between complexity (ML) and immediate value (Rule-based). Designed for explainability.\n- **Code Quality**: Modular code structure (`logic` vs `agent`), type hinting (`mypy`), and documentation. (Mention that `main.py` is the entry point but logic is separated).\n- **Problem Solving**: Identified that raw data allows for \"Company Level\" aggregation. We didn't just look at single accounts; we grouped by `company_name` to find the \"Internal Gap\".", "metadata": {"source": "salesagent-v2", "type": "project", "tech_stack": ["FastAPI", "OpenAI"], "section": "5. Case Study: Addressing the Evaluation Rubric", "tokens": 136}}
{"text": "### 6. Technical Deep Dive: Scaling & Robustness\n\n\n*Address how this scales (Interview Prep):*\n- **Concurrency**: Admitted current limitation (Global state in `main.py`) -> Proposed fix: Stateless API with Redis for session history.\n- **Data Volume**: Pandas works for 5k rows. For 5M rows, we would push logic to SQL/Snowflake (ELT).\n- **Feedback Loop**: Proposed \"Thumbs Up/Down\" in UI to capture labels for future Fine-Tuning (Llama 3).", "metadata": {"source": "salesagent-v2", "type": "project", "tech_stack": ["FastAPI", "OpenAI"], "section": "6. Technical Deep Dive: Scaling & Robustness", "tokens": 116}}
{"text": "### 7. Demo Scenario (The \"Craft\")\n\n\n*Setup the live demo:*\n- **Scenario**: A Sales Rep logs in Monday morning.\n- **Query 1**: \"Who should I call?\" -> Agent calls `get_top_leads` -> Returns high BNC score leads.\n- **Query 2**: \"Why them?\" -> Agent identifies the \" Gap\" (e.g., \"They have high revenue but low feature adoption\").\n- **Query 3**: \"Draft an email.\" -> Agent uses context to personalize the outreach.", "metadata": {"source": "salesagent-v2", "type": "project", "tech_stack": ["FastAPI", "OpenAI"], "section": "7. Demo Scenario (The \"Craft\")", "tokens": 114}}
{"text": "## 2. The Data Foundation (Slides 3-4) **[CRITICAL FOR STAFF ROLE]**\n\n\n*   **Slide 3: Data Dictionary & Landscape**\n    *   *Why*: You must establish trust in your inputs before showing outputs.\n    *   *Content*:\n        *   Source: `leads_clean.csv` (snapshot).\n        *   Volume: ~5k Accounts.\n        *   Schema: Revenue, Sessions, Contacts.\n*   **Slide 4: Key Assumptions (The \"Proxy\" Logic)**\n    *   *Why*: Show you understand the specific limitations of *this* dataset.\n    *   *Content*:\n        *   We assume `Sessions` = **Need**.\n        *   We assume `Contacts` = **Stickiness**.\n        *   We handle **Missing Data** by... (mention if any, or say \"Assumed Clean for Demo\").", "metadata": {"source": "salesagent-v2", "type": "project", "tech_stack": ["FastAPI", "OpenAI"], "section": "2. The Data Foundation (Slides 3-4) **[CRITICAL FOR STAFF ROLE]**", "tokens": 191}}
{"text": "## 3. The Methodology (Slides 5-6)\n\n\n*   **Slide 5: The BNC Framework** (Deterministic Layer)\n    *   **B**udget (Revenue > 75th pct)\n    *   **N**eed (Sessions > 75th pct)\n    *   **C**ontact (Contacts > 75th pct)\n*   **Slide 6: The \"Internal Gap\" Signal** (The unique insight)\n    *   \"Upselling to the median\": If peer accounts use X features, this account should too.", "metadata": {"source": "salesagent-v2", "type": "project", "tech_stack": ["FastAPI", "OpenAI"], "section": "3. The Methodology (Slides 5-6)", "tokens": 119}}
{"text": "## 4. The Solution & Demo (Slides 7-9)\n\n\n*   **Slide 7: Architecture (Current vs Target)**\n    *   *Critical for Staff*: Show you know current (CSV/Pandas) is just a prototype.\n    *   *Target State*: Snowflake -> Airflow -> Feature Store.\n*   **Slide 8: The Agent (Generative Layer)**\n    *   Role: \"The Coach\". It explains the *why*, not just the *who*.\n*   **Slide 9: Usage / Demo Highlights** (Screenshots)", "metadata": {"source": "salesagent-v2", "type": "project", "tech_stack": ["FastAPI", "OpenAI"], "section": "4. The Solution & Demo (Slides 7-9)", "tokens": 120}}
{"text": "## 5. Staff-Level Deep Dive (Slides 10-12)\n\n\n*   **Slide 10: Scalability & Constraints**\n    *   Addressing Latency (Async/Batch scoring).\n    *   Addressing Data Quality (Great Expectations).\n*   **Slide 11: Future Roadmap**\n    *   Phase 1: Robustness (CI/CD).\n    *   Phase 2: Feedback Loop (RLHF/Fine-tuning).\n*   **Slide 12: Q&A**\n\n---", "metadata": {"source": "salesagent-v2", "type": "project", "tech_stack": ["FastAPI", "OpenAI"], "section": "5. Staff-Level Deep Dive (Slides 10-12)", "tokens": 103}}
{"text": "### 2. Full-Stack Web Interface (Next.js + Tailwind)\n\n\n**Files**: [FastAPI Backend](file:///Users/apurva/Projects/AI_Agents/SalesAgent/src/api/main.py), [Next.js Frontend](dir:///Users/apurva/Projects/AI_Agents/SalesAgent/frontend)\n\nTransitioned to a professional web stack for maximum design control:\n- **\u269b\ufe0f Next.js 15**: Robust React framework for the frontend.\n- **\ud83c\udfa8 Tailwind CSS**: Utility-first CSS for the high-fidelity Slate SaaS design.\n- **\u26a1 FastAPI**: High-performance Python backend for the agent logic.\n- **\ud83c\udff7\ufe0f Smart Badges**: Real-time Tailwind-styled score badges (\ud83d\udd25 Priority 4, \ud83d\udfe0 Priority 3).\n- **\ud83d\udcf1 Responsive Layout**: Professional sidebar and chat interface that works on all devices.\n\n**To run the Backend:**\n```bash\nuv run uvicorn src.api.main:app --reload\n```\n\n**To run the Frontend:**\n```bash\ncd frontend\nnpm run dev\n```\n\n---", "metadata": {"source": "salesagent-v2", "type": "project", "tech_stack": ["FastAPI", "OpenAI"], "section": "2. Full-Stack Web Interface (Next.js + Tailwind)", "tokens": 234}}
{"text": "### Automated Tests\n\n\n**Scoring Logic**:\n- `test_calculate_score` PASSED\n- `test_internal_gap_calculation` PASSED\n- `test_threshold_calculation` PASSED\n- `test_zero_score` PASSED\n\n**Agent Logic (Unit Tests)**:\n- `test_tool_mapping` PASSED\n- `test_clear_history` PASSED\n- `test_get_top_leads_logic` PASSED\n- `test_chat_tool_execution_flow` PASSED\n\nTotal: 9 tests passed.", "metadata": {"source": "salesagent-v2", "type": "project", "tech_stack": ["FastAPI", "OpenAI"], "section": "Automated Tests", "tokens": 106}}
{"text": "### \ud83d\udcc2 File Structure\n\n\n\n```\nSalesAgent/\n\u251c\u2500\u2500 src/\n\u2502   \u251c\u2500\u2500 agent/\n\u2502   \u2502   \u2514\u2500\u2500 core.py         \u2190 \ud83d\ude80 Production agent\n\u2502   \u251c\u2500\u2500 logic/\n\u2502   \u2502   \u2514\u2500\u2500 scoring.py      \u2190 \ud83e\udde0 BNC scorer\n\u2502   \u2514\u2500\u2500 ui/\n\u2502       \u2514\u2500\u2500 app.py          \u2190 \ud83d\udda5\ufe0f Streamlit UI\n\u251c\u2500\u2500 docs/\n\u2502   \u251c\u2500\u2500 architecture.md     \u2190 \ud83c\udfd7\ufe0f With diagrams\n\u2502   \u251c\u2500\u2500 assumptions.md      \u2190 \ud83d\udcdd Context\n\u2502   \u2514\u2500\u2500 business_case.md    \u2190 \ud83d\udcb0 ROI analysis\n\u2514\u2500\u2500 tests/\n    \u2514\u2500\u2500 test_scoring.py     \u2190 \u2705 9 tests passing\n```\n\n---", "metadata": {"source": "salesagent-v2", "type": "project", "tech_stack": ["FastAPI", "OpenAI"], "section": "\ud83d\udcc2 File Structure", "tokens": 159}}
{"text": "## High-Level Architecture\n\n\n\n```mermaid\nflowchart TD\n    subgraph Frontend[\"Frontend (Next.js)\"]\n        UI[\"React Components\"]\n        API_Client[\"API Client\"]\n    end\n    \n    subgraph Backend[\"Backend (FastAPI)\"]\n        API[\"API Layer\"]\n        Agent[\"SalesAgent Class\"]\n        Tools[\"Tool Functions\"]\n    end\n    \n    subgraph Logic[\"Business Logic\"]\n        Scorer[\"LeadScorer\"]\n        BNC[\"BNC Framework\"]\n    end\n    \n    subgraph Data[\"Data Layer\"]\n        CSV[\"leads_clean.csv\"]\n        DataFrame[\"Pandas DataFrame\"]\n    end\n    \n    subgraph External[\"External API\"]\n        OpenAI[\"OpenAI GPT-4o-mini\"]\n    end\n    \n    UI --> API_Client\n    API_Client <-->|REST| API\n    API --> Agent\n    Agent --> Tools\n    Agent <--> OpenAI\n    Tools --> Scorer\n    Scorer --> BNC\n    BNC --> DataFrame\n    DataFrame --> CSV\n```\n\n---", "metadata": {"source": "salesagent", "type": "project", "tech_stack": ["FastAPI", "OpenAI"], "section": "High-Level Architecture", "tokens": 213}}
{"text": "## \ud83d\udd04 Data Flow\n\n\n\n```mermaid\nsequenceDiagram\n    participant User\n    participant NextJS as Frontend (Next.js)\n    participant FastAPI as Backend API\n    participant Agent\n    participant OpenAI\n    \n    User->>NextJS: \"Who should I call?\"\n    NextJS->>FastAPI: POST /chat {message}\n    FastAPI->>Agent: chat(message)\n    Agent->>OpenAI: Request with tools\n    OpenAI-->>Agent: Suggest Tool: get_top_leads()\n    Agent->>Agent: Execute get_top_leads()\n    Agent->>OpenAI: Return Tool Result\n    OpenAI-->>Agent: Natural Language Response\n    Agent-->>FastAPI: Return Text\n    FastAPI-->>NextJS: JSON Response\n    NextJS-->>User: Render Message Bubble\n```\n\n---", "metadata": {"source": "salesagent", "type": "project", "tech_stack": ["FastAPI", "OpenAI"], "section": "\ud83d\udd04 Data Flow", "tokens": 177}}
{"text": "## \ud83d\udee0\ufe0f Technology Decisions\n\n\n\n| Decision | Choice | Rationale |\n|:---|:---|:---|\n| **Frontend** | **Next.js + Tailwind** | Staff-level polish, component reusability, production standard. |\n| **Backend** | **FastAPI** | High performance, auto-docs, native async support for AI. |\n| **LLM** | OpenAI GPT-4o-mini | Cost-effective, sufficient reasoning capability. |\n| **Data** | CSV + Pandas | Simplicity for the \"Craft Demo\" constraint. |\n\n---", "metadata": {"source": "salesagent", "type": "project", "tech_stack": ["FastAPI", "OpenAI"], "section": "\ud83d\udee0\ufe0f Technology Decisions", "tokens": 121}}
{"text": "## \ud83d\udcc2 File Structure\n\n\n\n```\nSalesAgent/\n\u251c\u2500\u2500 frontend/                # Next.js Application\n\u2502   \u251c\u2500\u2500 src/app/             # React Pages\n\u2502   \u2514\u2500\u2500 public/              # Static assets\n\u251c\u2500\u2500 src/\n\u2502   \u251c\u2500\u2500 api/\n\u2502   \u2502   \u2514\u2500\u2500 main.py          # FastAPI Server\n\u2502   \u251c\u2500\u2500 agent/\n\u2502   \u2502   \u2514\u2500\u2500 core.py          # Agent Logic\n\u2502   \u251c\u2500\u2500 logic/\n\u2502   \u2502   \u2514\u2500\u2500 scoring.py       # BNC Scoring\n\u2502   \u2514\u2500\u2500 ui/\n\u2502       \u2514\u2500\u2500 app.py           # (Legacy) Streamlit\n\u251c\u2500\u2500 data/\n\u2502   \u2514\u2500\u2500 processed/           # CSV Data\n\u2514\u2500\u2500 docs/\n    \u251c\u2500\u2500 architecture.md      # This file\n    \u2514\u2500\u2500 requirements.md      # PRD\n```\n\n\n\n---", "metadata": {"source": "salesagent", "type": "project", "tech_stack": ["FastAPI", "OpenAI"], "section": "\ud83d\udcc2 File Structure", "tokens": 184}}
{"text": "## 2. Lead Type\n\n\n\n**Assumption**: These are **expansion/upsell opportunities** (not cold leads).\n\n**Evidence**:\n- `days_since_signup` \u2192 Accounts already exist\n- `sessions_per_month`, `contacts_per_month` \u2192 Usage data available\n- `paid_optional_features_count` \u2192 Already monetized to some degree\n\n**Implication**: Prioritization should identify \"engagement vs monetization gap\"\n- High usage + low paid features = strong upsell signal\n- High revenue = spending power indicator\n\n---", "metadata": {"source": "salesagent", "type": "project", "tech_stack": ["FastAPI", "OpenAI"], "section": "2. Lead Type", "tokens": 113}}
{"text": "## 6. Data Structure: Multi-Account Companies\n\n\n\n**Discovery**: Every company in the dataset has multiple accounts (avg ~47 per company).\n\n**Interpretation**: These represent:\n- Different departments/divisions using the product independently\n- Separate budgets and decision-makers\n- Enterprise/mid-market companies with decentralized purchasing\n\n**Implication for Agent**:\n- Account-level scoring (who to call)\n- Company-level insights (enterprise opportunity detection)\n- Cross-account pattern recognition\n- Strategic account planning (not just tactical lead prioritization)\n\n**Example**: \n\"Complete Technologie\" has 62 accounts:\n- 30 with <3 features (upsell targets)\n- 12 with 30+ sessions (engaged users)\n- Combined revenue: $900M+ (enterprise budget)\n\u2192 Recommendation: Coordinate multi-account strategy\n\n---", "metadata": {"source": "salesagent", "type": "project", "tech_stack": ["FastAPI", "OpenAI"], "section": "6. Data Structure: Multi-Account Companies", "tokens": 169}}
{"text": "## 5. Column Interpretations\n\n\n\n**No data dictionary was provided.** These interpretations are assumptions:\n\n| Column | Our Interpretation | Confidence |\n|--------|-------------------|------------|\n| `sessions_per_month` | Product login sessions (usage) | Medium - could be sales meetings |\n| `contacts_per_month` | Active users/seats at account | Medium - could be support contacts |\n| `days_since_signup` | Account age | High |\n| `revenue_usd` | Company annual revenue | High |\n\n**Interview note**: First question to business would be \"Can I get a data dictionary?\"\n\n---", "metadata": {"source": "salesagent", "type": "project", "tech_stack": ["FastAPI", "OpenAI"], "section": "5. Column Interpretations", "tokens": 125}}
{"text": "## 6. Scoring Logic Rationale\n\n\n\n**Why equal weights?**\n- No historical conversion data to validate which signals matter more\n- Starting with assumptions we can't defend would be bad practice\n- In production: A/B test weights, optimize based on actual conversions\n\n**Why 75th percentile thresholds?**\n- Top 25% is a standard, defensible statistical approach\n- Dynamic: adapts if customer base changes\n- Easy to explain: \"We target the top quarter\"\n\n**Why Internal Gap signal?**\n- Data showed 105 companies with ~47 accounts each\n- If one department adopted features, others are warm leads\n- Sales angle: \"Your colleagues in [dept] already use this\"\n\n---", "metadata": {"source": "salesagent", "type": "project", "tech_stack": ["FastAPI", "OpenAI"], "section": "6. Scoring Logic Rationale", "tokens": 147}}
{"text": "## 7. What We Chose NOT to Include\n\n\n\n| Column | Why Excluded from Scoring |\n|--------|---------------------------|\n| `number_of_employees` | Correlation with features: -0.002 (no signal) |\n| `number_of_subsidiaries` | Correlation with features: -0.0004 (no signal) |\n| `days_since_signup` | Correlation: -0.008. Used as context, not score |\n\n**Key insight**: Almost no correlation between any column and `paid_optional_features_count`. This validates the \"gap\" approach - opportunity is about relative position, not absolute values.", "metadata": {"source": "salesagent", "type": "project", "tech_stack": ["FastAPI", "OpenAI"], "section": "7. What We Chose NOT to Include", "tokens": 133}}
{"text": "## 1. Data Schema\n\n\n\n| Column | Type | Description | Range/Notes |\n|--------|------|-------------|-------------|\n| `account_id` | int | Unique account identifier | |\n| `account_contact_name` | string | Contact person name | |\n| `phone_number` | string | Contact phone | |\n| `email` | string | Contact email | |\n| `company_name` | string | Company name | 105 unique |\n| `days_since_signup` | int | Account age in days | 1 - 1,825 |\n| `number_of_subsidiaries` | int | Company subsidiaries | 0 - 8 |\n| `revenue_usd` | float | Annual revenue | $145K - $49M |\n| `number_of_employees` | int | Company headcount | 20 - 92K |\n| `sessions_per_month` | int | Monthly product sessions | 0 - 40 |\n| `contacts_per_month` | int | Monthly active users | 0 - 20 |\n| `paid_optional_features_count` | int | Paid features count | 0 - 7 |\n\n---", "metadata": {"source": "salesagent", "type": "project", "tech_stack": ["FastAPI", "OpenAI"], "section": "1. Data Schema", "tokens": 236}}
{"text": "### 3.1 Signals\n\n\n\n| Signal | Column | Threshold | Rationale |\n|--------|--------|-----------|-----------|\n| **B**udget | `revenue_usd` | >= $22M (75th pct) | Capacity to pay |\n| **N**eed | `sessions_per_month` | >= 30 (75th pct) | Product engagement |\n| **C**ontacts | `contacts_per_month` | >= 15 (75th pct) | Stickiness |\n| **Internal Gap** | `paid_optional_features_count` | < company median | Behind peers |", "metadata": {"source": "salesagent", "type": "project", "tech_stack": ["FastAPI", "OpenAI"], "section": "3.1 Signals", "tokens": 122}}
{"text": "### 3.3 Score Distribution\n\n\n\n| Score | Count | % | Tier |\n|-------|-------|---|------|\n| 4 | 30 | 0.6% | Hot |\n| 3 | 322 | 6.4% | High |\n| 2 | 1,266 | 25.3% | Medium |\n| 1 | 2,051 | 41.0% | Low |\n| 0 | 1,330 | 26.6% | Cold |\n\n---", "metadata": {"source": "salesagent", "type": "project", "tech_stack": ["FastAPI", "OpenAI"], "section": "3.3 Score Distribution", "tokens": 108}}
{"text": "### 4. Dynamic Port Mapping\n\n\n- **Issue**: Render assigns a dynamic port via the `$PORT` environment variable, but the `Dockerfile` was hardcoded to `8000`.\n- **Solution**: Updated the `Dockerfile` `CMD` to use `sh -c` for environment variable expansion:\n  ```dockerfile\n  CMD [\"sh\", \"-c\", \"uvicorn src.api.main:app --host 0.0.0.0 --port ${PORT:-8000}\"]\n  ```", "metadata": {"source": "salesagent", "type": "project", "tech_stack": ["FastAPI", "OpenAI"], "section": "4. Dynamic Port Mapping", "tokens": 109}}
{"text": "## 5. Post-Deployment: Update Backend CORS\n\n\nOnce deployed, Vercel will assign a URL to your project (e.g., `https://sales-agent-frontend.vercel.app`). You must allow this URL in your Render backend settings.\n\n1.  Copy your new Vercel URL.\n2.  Go to your **Render Dashboard**.\n3.  Select your `sales-agent-api` service.\n4.  Go to **Environment**.\n5.  Edit the `ALLOWED_ORIGINS` variable (or create it if it doesn't exist).\n6.  Add your Vercel URL to the list (comma-separated).\n    *   **Example**: `http://localhost:3000,http://localhost:3001,https://your-app.vercel.app`\n\n\n\n---", "metadata": {"source": "salesagent", "type": "project", "tech_stack": ["FastAPI", "OpenAI"], "section": "5. Post-Deployment: Update Backend CORS", "tokens": 164}}
{"text": "### Slide 2: The Problem (Context)\n\n\n- **Visual**: A frustrated salesperson staring at a spreadsheet with 5,000 rows.\n- **Bullets**:\n  - Sales reps spend **40% of time** just finding who to call.\n  - \"Cherry-picking\" bias leads to missed opportunities.\n  - High volume of data (Revenue, Sessions, Contacts) is hard to process mentally.\n- **Talking Point**: \"We have data, but we lack **insight**. Our reps are drowning in rows but starving for context.\"", "metadata": {"source": "salesagent", "type": "project", "tech_stack": ["FastAPI", "OpenAI"], "section": "Slide 2: The Problem (Context)", "tokens": 114}}
{"text": "### Slide 3: The Solution (BNC + Internal Gap)\n\n\n- **Visual**: Funnel diagram showing Raw Leads -> BNC Filter -> Top Targets.\n- **Framework**:\n  - \ud83d\udcb0 **Budget**: Top 25% Revenue\n  - \ud83d\udcc8 **Need**: Top 25% Session Activity\n  - \ud83d\udc65 **Stickiness**: Top 25% Contact Count\n  - \ud83c\udfaf **Gap**: Usage < Company Median (Calculated)\n- **Talking Point**: \"We don't need 'fancy' AI for everything. We need a deterministic scoring layer first to filter the signal, *then* we specific AI for the communication.\"", "metadata": {"source": "salesagent", "type": "project", "tech_stack": ["FastAPI", "OpenAI"], "section": "Slide 3: The Solution (BNC + Internal Gap)", "tokens": 137}}
{"text": "### Slide 4: System Architecture (Current vs. Future)\n\n\n- **Visual**:\n  - **Left (Current)**: CSV -> Python Logic -> **FastAPI (Backend)** -> **Next.js (Frontend)**.\n  - **Right (Scalable)**: Data Warehouse (Snowflake) -> Airflow (ETL) -> Vector DB + Metadata -> Orchestration Layer (Router) -> UI.\n- **Talking Point**: \"Today's demo uses a modern decoupled architecture (React/FastAPI) which is closer to production standards than a simple Streamlit prototype.\"", "metadata": {"source": "salesagent", "type": "project", "tech_stack": ["FastAPI", "OpenAI"], "section": "Slide 4: System Architecture (Current vs. Future)", "tokens": 118}}
{"text": "### Slide 5: The \"Craft\" (Demo Highlights)\n\n\n- **Visual**: Screenshot of the Chat Interface.\n- **Key Features to Demo**:\n  1. **\"Who should I call?\"** (Shows automated ranking).\n  2. **\"Why them?\"** (Shows interpretability/reasoning).\n  3. **\"What do I say?\"** (Shows generative context).\n- **Talking Point**: \"It's not just a list; it's a coaching tool. It gives the 'Why' behind the ranking.\"\n\n---", "metadata": {"source": "salesagent", "type": "project", "tech_stack": ["FastAPI", "OpenAI"], "section": "Slide 5: The \"Craft\" (Demo Highlights)", "tokens": 114}}
{"text": "### 1. \"We used CSV here, but real data is messy. How do we automate cleaning?\"\n\n\n**Answer**:\n- **Current**: We assume a clean export for the demo.\n- **Real World**: We would implement an **ETL Pipeline** (e.g., dbt + Airflow).\n- **Data Quality (DQ) Checks**:\n  - Use a tool like **Great Expectations** or **dbt tests** in the pipeline.\n  - *Example*: `expect_column_values_to_be_not_null(\"revenue\")`.\n  - If data is \"dirty\" (e.g., text in revenue fields), the pipeline fails proactively *before* it hits the agent, alerting the data engineer.", "metadata": {"source": "salesagent", "type": "project", "tech_stack": ["FastAPI", "OpenAI"], "section": "1. \"We used CSV here, but real data is messy. How do we automate cleaning?\"", "tokens": 149}}
{"text": "### 2. \"What if extra columns are added? Is the code intelligent enough?\"\n\n\n**Answer**:\n- **Strictly Speaking**, No. The current code (`scoring.py`) is **brittle** because it hardcodes specific column names (`revenue_usd`, `sessions_per_month`).\n- **Impact**:\n  - *Extra Columns*: Ignored (Pandas default). The framework continues to work but ignores new signals.\n  - *Renamed/Missing Columns*: The application crashes.\n- **The Fix**: Move configuration to a YAML config file.\n  - Define `signals: [\"revenue_usd\", \"new_signal_x\"]`.\n  - The scorer dynamically iterates over this config to generate the score, making it \"intelligent\" enough to adapt to schema changes without code rewrites.", "metadata": {"source": "salesagent", "type": "project", "tech_stack": ["FastAPI", "OpenAI"], "section": "2. \"What if extra columns are added? Is the code intelligent enough?\"", "tokens": 169}}
{"text": "### 3. \"How do we handle 20 concurrent sales agents?\" (CRITICAL FINDING)\n\n\n**Answer**:\n- **Current Bottleneck**: \"I identified a critical concurrency bug in the current code.\"\n  - The `agent` instance in `main.py` is initialized globally: `agent = create_agent()`.\n  - This means `agent.conversation_history` is shared across ALL users.\n- **The Fix**:\n  - **Stateless Architecture**: The backend should just handle requests.\n  - **Session State**: Store conversation history in the user's session (e.g., Redis or strictly in the Next.js frontend state), NOT in the global Agent class instance.\n  - **Read-Only Data**: The `Scorer` (heavy read-only data) *can* be a global singleton. The `Agent` (stateful) must be instantiated per-request or per-user.", "metadata": {"source": "salesagent", "type": "project", "tech_stack": ["FastAPI", "OpenAI"], "section": "3. \"How do we handle 20 concurrent sales agents?\" (CRITICAL FINDING)", "tokens": 185}}
{"text": "### 4. \"How do we automate deployments (CI/CD)?\"\n\n\n**Answer**:\n- **Current**: Manual push to Render.\n- **Scalable**: GitHub Actions Pipeline.\n  1. **Lint/Test**: On PR, run `pytest` and `flake8`.\n  2. **Build**: Build Docker container.\n  3. **Deploy (Staging)**: Push to Staging environment.\n  4. **Integration Test**: Run synthetic agent queries against Staging.\n  5. **Deploy (Prod)**: Auto-promote if tests pass.", "metadata": {"source": "salesagent", "type": "project", "tech_stack": ["FastAPI", "OpenAI"], "section": "4. \"How do we automate deployments (CI/CD)?\"", "tokens": 125}}
{"text": "### 5. \"Data is in emails. How do we automate that?\"\n\n\n**Answer**:\n- We need an **Ingestion Connector** (e.g., SendGrid Inbound Parse or Microsoft Graph API).\n- **Workflow**:\n  1. Trigger: New Email.\n  2. **Extraction Agent** (New LLM component): \"Complete this JSON schema based on the email body.\"\n  3. **Validation**: Check if extracted revenue/contact info looks valid.\n  4. **Upsert**: Push to the Database/CSV.\n- *Challenge*: Emails are unstructured. We will need a strong parsing prompt and manual fallback (\"Human in the Loop\") for low-confidence parsings.", "metadata": {"source": "salesagent", "type": "project", "tech_stack": ["FastAPI", "OpenAI"], "section": "5. \"Data is in emails. How do we automate that?\"", "tokens": 147}}
{"text": "### 6. \"How do we track conversions and make the LLM learn?\"\n\n\n**Answer**:\n- **Do we have an LLM model?**: No, we use a frozen API model (GPT-4o). It does *not* learn online.\n- **The Loop**:\n  1. **Feedback UI**: Add \"\ud83d\udc4d/\ud83d\udc4e - Was this lead good?\" buttons in the UI.\n  2. **Outcome Tracking**: Integrate with CRM (Salesforce) to see if \"Won Deal\" flags appear for high-scored leads.\n  3. **Optimization**:\n    - *Short term*: We tune the *prompt* (Few-Shot examples of successful leads).\n    - *Long term*: We fine-tune a smaller model (Llama 3) on our proprietary \"Good Lead\" dataset to replace the generic GPT-4o, lowering costs and increasing specificity.", "metadata": {"source": "salesagent", "type": "project", "tech_stack": ["FastAPI", "OpenAI"], "section": "6. \"How do we track conversions and make the LLM learn?\"", "tokens": 191}}
{"text": "### 7. \"Scaling to Multiple Models (Router Pattern)\"\n\n\n**Answer**:\n- **Reasoning**: GPT-4o is expensive. Claude is great for writing. Gemini is massive context.\n- **Implementation**:\n  - Build a **Router** function.\n  - *Input*: \"Draft an email to Kevin.\" -> *Router*: \"This is a creative task.\" -> *Route*: **Claude 3.5 Sonnet**.\n  - *Input*: \"Filter leads by revenue.\" -> *Router*: \"This is a logic task.\" -> *Route*: **Llama 3 (local/fast)** or **simple SQL**.\n- **Code Change**: Abstract `self.client` into a `ModelProviderFactory` that accepts a `task_type` argument.\n\n---", "metadata": {"source": "salesagent", "type": "project", "tech_stack": ["FastAPI", "OpenAI"], "section": "7. \"Scaling to Multiple Models (Router Pattern)\"", "tokens": 163}}
{"text": "## \ud83d\udd0d Part 3: Codebase Breakdown (The Honest Assessment)\n\n\n\n| Aspect | Status | Verdict |\n| :--- | :--- | :--- |\n| **Flexibility** | \ud83d\udd34 Rigid | Hardcoded logic in `scoring.py`. Cannot handle schema changes dynamically. |\n| **Error Handling** | \ud83d\udfe1 Partial | Basic try/except for lookups. No global error boundary. If OpenAI API fails, the app likely crashes or hangs. |\n| **Intelligence** | \ud83d\udfe1 Basic | It's a \"Rule-based System\" (BNC) wrapped in an LLM interface. The \"Intelligence\" is in the scoring math, not the AI reasoning. |\n| **Concurrency** | \ud83d\udd34 Broken | **Critical Issue**: Global state sharing would cause cross-talk between agents. |\n| **Scalability** | \ud83d\udfe2 Decent | The logic (Pandas) is fast for <100k rows. For >1M rows, we'd need Spark or SQL pushdown. |\n\n---", "metadata": {"source": "salesagent", "type": "project", "tech_stack": ["FastAPI", "OpenAI"], "section": "\ud83d\udd0d Part 3: Codebase Breakdown (The Honest Assessment)", "tokens": 211}}
{"text": "## \ud83d\ude80 Part 4: Future Roadmap (If given more time)\n\n\n\n**Must Haves (Priority 1)**:\n1. **Fix Concurrency**: Refactor `SalesAgent` to be stateless; move history to a database or frontend state (Next.js).\n2. **Robustness**: wrap OpenAI calls in `tenacity` retry logic (for API timeouts).\n\n**Nice to Haves (Priority 2)**:\n1. **Dynamic Config**: Move thresholds (75th percentile) to a `config.yaml` so business users can tweak \"Stictness\" without code changes.\n2. **CRM Integration**: Instead of reading CSV context processing, read directly from Salesforce/HubSpot API.\n\n\n\n---", "metadata": {"source": "salesagent", "type": "project", "tech_stack": ["FastAPI", "OpenAI"], "section": "\ud83d\ude80 Part 4: Future Roadmap (If given more time)", "tokens": 151}}
{"text": "## From: presentation_slides.md\n\n\n\n---\nmarp: true\ntheme: default\npaginate: true\nbackgroundColor: #ffffff\nstyle: |\n  section {\n    font-family: 'Arial', sans-serif;\n  }\n  h1 {\n    color: #2c3e50;\n  }\n  h2 {\n    color: #34495e;\n  }\n  .lead {\n    font-size: 1.5rem;\n    color: #555;\n  }\n---\n\n# From Noise to Signal", "metadata": {"source": "salesagent", "type": "project", "tech_stack": ["FastAPI", "OpenAI"], "section": "From: presentation_slides.md", "tokens": 105}}
{"text": "## Intelligent Sales Lead Prioritization\n\n\n\n**Presenter**: Data Scientist, Intelligent Automation\n*Date: January 12, 2026*\n\n---\n\n# The Problem: Drowning in Data\n\n- **Overview**: Sales reps spend **40% of their time** just finding who to call.\n- **Pain Point**: \"Cherry-picking\" leads causes missed opportunities.\n- **Challenge**:\n  - High volume of data (Revenue, Sessions, Contacts).\n  - Manual filtering is slow and biased.\n- **Impact**: We have data, but we lack *insight*.\n\n---\n\n# The Solution: BNC + Internal Gap Framework\n\nWe combine deterministic scoring with AI reasoning.\n\n1. **\ud83d\udcb0 Budget**: Top 25% Revenue (> $X M)\n2. **\ud83d\udcc8 Need**: Top 25% Session Activity (> Y sessions)\n3. **\ud83d\udc65 Stickiness**: Top 25% Contact Count (> Z contacts)\n4. **\ud83c\udfaf Internal Gap**: \n   - *Key Signal*: Usage < Company Median\n   - *Opportunity*: Upsell to peer level.\n\n---\n\n# System Architecture", "metadata": {"source": "salesagent", "type": "project", "tech_stack": ["FastAPI", "OpenAI"], "section": "Intelligent Sales Lead Prioritization", "tokens": 232}}
{"text": "## Future (Scalable)\n\n\n`Snowflake/DW` \u2192 `Airflow (ETL)` \u2192 `Vector DB` \u2192 `Agent Router` \u2192 `Web UI`\n\n> **Note**: The core logic is decoupled, ready to be lifted-and-shifted to a cloud pipeline.\n\n---\n\n# The \"Craft\": Demo Highlights\n\n1. **\"Who should I call?\"**\n   - Automated ranking based on the BNC score (0-4).\n   \n2. **\"Why them?\"**\n   - Explainable AI: \"High budget, high need, but low feature adoption.\"\n\n3. **\"What do I say?\"**\n   - Generative context: Tailored talking points for the specific contact.\n\n---\n\n# Scalability & Robustness\n\n- **Data Pipelines**:\n  - Move from CSV to **ETL Pipelines** (Airflow/dbt) with Data Quality checks.\n  - Handle dirty data *before* it reaches the agent.\n  \n- **Concurrency**:\n  - **Refactor Identified**: Move from Global Singleton to **Stateless Session Architecture** (Redis/Session State) to support 20+ simultaneous agents.\n\n- **Deployment**:\n  - Implement **CI/CD** (GitHub Actions) for automated testing and deployment.\n\n---\n\n# Future Roadmap\n\n- **Phase 1: Robustness**\n  - Fix concurrency (Stateless).\n  - Add API retry logic (Tenacity).\n\n- **Phase 2: Intelligence**\n  - Dynamic Configuration (YAML-based scoring).\n  - **Router Pattern**: Use Claude for writing, GPT-4o for reasoning.\n\n- **Phase 3: Integration**\n  -  Direct CRM Integration (Salesforce API).\n  -  Email Ingestion Connectors.\n\n---\n\n# Q&A\n\n**Thank You**\n\n\n\n---", "metadata": {"source": "salesagent", "type": "project", "tech_stack": ["FastAPI", "OpenAI"], "section": "Future (Scalable)", "tokens": 370}}
{"text": "### 2.1 Lead Scoring Engine\n\n\n- **FR-1**: Must calculate a score (0-4) based on four binary signals.\n- **FR-2**: **Budget Signal**: Account revenue must be in the top 25% of the dataset.\n- **FR-3**: **Need Signal**: Account sessions per month must be in the top 25% of the dataset.\n- **FR-4**: **Stickiness Signal**: Active contacts must be in the top 25% of the dataset.\n- **FR-5**: **Internal Gap Signal**: Account must have fewer paid features than the median for its parent company.", "metadata": {"source": "salesagent", "type": "project", "tech_stack": ["FastAPI", "OpenAI"], "section": "2.1 Lead Scoring Engine", "tokens": 140}}
{"text": "### 2.2 Conversational Agent\n\n\n- **FR-6**: Must provide a natural language interface for querying leads.\n- **FR-7**: Must support \"Get Top Leads\" query with configurable thresholds.\n- **FR-8**: Must support \"Account Deep Dive\" for specific contact names or IDs.\n- **FR-9**: Must support \"Company Insights\" to show cross-account opportunities.\n- **FR-10**: Must maintain session context (memory) for follow-up questions.", "metadata": {"source": "salesagent", "type": "project", "tech_stack": ["FastAPI", "OpenAI"], "section": "2.2 Conversational Agent", "tokens": 104}}
{"text": "### 2. Full-Stack Web Interface (Next.js + Tailwind)\n\n\n**Files**: [FastAPI Backend](file:///Users/apurva/Projects/AI_Agents/SalesAgent/src/api/main.py), [Next.js Frontend](dir:///Users/apurva/Projects/AI_Agents/SalesAgent/frontend)\n\nTransitioned to a professional web stack for maximum design control:\n- **\u269b\ufe0f Next.js 15**: Robust React framework for the frontend.\n- **\ud83c\udfa8 Tailwind CSS**: Utility-first CSS for the high-fidelity Slate SaaS design.\n- **\u26a1 FastAPI**: High-performance Python backend for the agent logic.\n- **\ud83c\udff7\ufe0f Smart Badges**: Real-time Tailwind-styled score badges (\ud83d\udd25 Priority 4, \ud83d\udfe0 Priority 3).\n- **\ud83d\udcf1 Responsive Layout**: Professional sidebar and chat interface that works on all devices.\n\n**To run the Backend:**\n```bash\nuv run uvicorn src.api.main:app --reload\n```\n\n**To run the Frontend:**\n```bash\ncd frontend\nnpm run dev\n```\n\n---", "metadata": {"source": "salesagent", "type": "project", "tech_stack": ["FastAPI", "OpenAI"], "section": "2. Full-Stack Web Interface (Next.js + Tailwind)", "tokens": 234}}
{"text": "### Automated Tests\n\n\n**Scoring Logic**:\n- `test_calculate_score` PASSED\n- `test_internal_gap_calculation` PASSED\n- `test_threshold_calculation` PASSED\n- `test_zero_score` PASSED\n\n**Agent Logic (Unit Tests)**:\n- `test_tool_mapping` PASSED\n- `test_clear_history` PASSED\n- `test_get_top_leads_logic` PASSED\n- `test_chat_tool_execution_flow` PASSED\n\nTotal: 9 tests passed.", "metadata": {"source": "salesagent", "type": "project", "tech_stack": ["FastAPI", "OpenAI"], "section": "Automated Tests", "tokens": 106}}
{"text": "### \ud83d\udcc2 File Structure\n\n\n\n```\nSalesAgent/\n\u251c\u2500\u2500 src/\n\u2502   \u251c\u2500\u2500 agent/\n\u2502   \u2502   \u2514\u2500\u2500 core.py         \u2190 \ud83d\ude80 Production agent\n\u2502   \u251c\u2500\u2500 logic/\n\u2502   \u2502   \u2514\u2500\u2500 scoring.py      \u2190 \ud83e\udde0 BNC scorer\n\u2502   \u2514\u2500\u2500 ui/\n\u2502       \u2514\u2500\u2500 app.py          \u2190 \ud83d\udda5\ufe0f Streamlit UI\n\u251c\u2500\u2500 docs/\n\u2502   \u251c\u2500\u2500 architecture.md     \u2190 \ud83c\udfd7\ufe0f With diagrams\n\u2502   \u251c\u2500\u2500 assumptions.md      \u2190 \ud83d\udcdd Context\n\u2502   \u2514\u2500\u2500 business_case.md    \u2190 \ud83d\udcb0 ROI analysis\n\u2514\u2500\u2500 tests/\n    \u2514\u2500\u2500 test_scoring.py     \u2190 \u2705 9 tests passing\n```\n\n---", "metadata": {"source": "salesagent", "type": "project", "tech_stack": ["FastAPI", "OpenAI"], "section": "\ud83d\udcc2 File Structure", "tokens": 159}}
